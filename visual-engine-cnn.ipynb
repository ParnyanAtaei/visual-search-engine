{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5186786,"sourceType":"datasetVersion","datasetId":3015609}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install requirements","metadata":{}},{"cell_type":"code","source":"!pip install faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T14:27:52.976501Z","iopub.execute_input":"2025-07-14T14:27:52.976668Z","iopub.status.idle":"2025-07-14T14:28:00.086159Z","shell.execute_reply.started":"2025-07-14T14:27:52.976653Z","shell.execute_reply":"2025-07-14T14:28:00.085184Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.11.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Import library","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision.models as models\nimport torchvision.transforms as T\nfrom PIL import Image\nimport numpy as np\nimport faiss\nfrom tqdm import tqdm\nimport gradio as gr\nimport pickle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T14:28:06.045395Z","iopub.execute_input":"2025-07-14T14:28:06.046034Z","iopub.status.idle":"2025-07-14T14:28:21.882117Z","shell.execute_reply.started":"2025-07-14T14:28:06.045999Z","shell.execute_reply":"2025-07-14T14:28:21.881546Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"IMAGE_FOLDER = \"/kaggle/input/2017-2017/train2017/train2017\"\nFEATURES_PATH = \"cnn_image_features.npy\"\nPATHS_PATH = \"cnn_image_paths.pkl\"\nBATCH_SIZE = 32\nTOP_K = 5\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T14:28:26.223129Z","iopub.execute_input":"2025-07-14T14:28:26.223610Z","iopub.status.idle":"2025-07-14T14:28:26.322247Z","shell.execute_reply.started":"2025-07-14T14:28:26.223588Z","shell.execute_reply":"2025-07-14T14:28:26.321438Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Load CNN model(resnet50)\nRemove the last layer(fully connected layer)\nAnd process images ","metadata":{}},{"cell_type":"code","source":"# Load CNN\ncnn_model = models.resnet50(pretrained=True)\ncnn_model = torch.nn.Sequential(*(list(cnn_model.children())[:-1]))\ncnn_model.eval()\ncnn_model.to(device)\n\ncnn_preprocess = T.Compose([\n    T.Resize(256),\n    T.CenterCrop(224),\n    T.ToTensor(),\n    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T14:28:28.845744Z","iopub.execute_input":"2025-07-14T14:28:28.846396Z","iopub.status.idle":"2025-07-14T14:28:30.309555Z","shell.execute_reply.started":"2025-07-14T14:28:28.846371Z","shell.execute_reply":"2025-07-14T14:28:30.308961Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 187MB/s] \n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Feature extraction function\nIterates through image_paths in batches, loads and preprocesses each image, feeds it through the cnn_model to get its feature vector, and then normalizes these features.","metadata":{}},{"cell_type":"code","source":"\nimage_paths = [os.path.join(IMAGE_FOLDER, fname) for fname in os.listdir(IMAGE_FOLDER)\n               if fname.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\ndef extract_cnn_features(image_paths, batch_size=BATCH_SIZE):\n    features = []\n    for i in tqdm(range(0, len(image_paths), batch_size), desc=\"Extracting CNN features\"):\n        batch_paths = image_paths[i:i+batch_size]\n        images = [cnn_preprocess(Image.open(p).convert(\"RGB\")).unsqueeze(0) for p in batch_paths]\n        images = torch.cat(images).to(device)\n        with torch.no_grad():\n            batch_features = cnn_model(images).squeeze(-1).squeeze(-1)\n            batch_features = batch_features / batch_features.norm(dim=-1, keepdim=True)\n        features.append(batch_features.cpu().numpy())\n    return np.concatenate(features, axis=0).astype(\"float32\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T14:28:36.806613Z","iopub.execute_input":"2025-07-14T14:28:36.807134Z","iopub.status.idle":"2025-07-14T14:28:38.122675Z","shell.execute_reply.started":"2025-07-14T14:28:36.807110Z","shell.execute_reply":"2025-07-14T14:28:38.121956Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Load or compute features\nif os.path.exists(FEATURES_PATH) and os.path.exists(PATHS_PATH):\n    image_features = np.load(FEATURES_PATH)\n    with open(PATHS_PATH, \"rb\") as f:\n        saved_paths = pickle.load(f)\n    if set(saved_paths) != set(image_paths):\n        print(\"Image set changed, re-extracting features...\")\n        image_features = extract_cnn_features(image_paths)\n        np.save(FEATURES_PATH, image_features)\n        with open(PATHS_PATH, \"wb\") as f:\n            pickle.dump(image_paths, f)\nelse:\n    image_features = extract_cnn_features(image_paths)\n    np.save(FEATURES_PATH, image_features)\n    with open(PATHS_PATH, \"wb\") as f:\n        pickle.dump(image_paths, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T14:28:42.138485Z","iopub.execute_input":"2025-07-14T14:28:42.139027Z","iopub.status.idle":"2025-07-14T15:03:54.633201Z","shell.execute_reply.started":"2025-07-14T14:28:42.139002Z","shell.execute_reply":"2025-07-14T15:03:54.632545Z"}},"outputs":[{"name":"stderr","text":"Extracting CNN features: 100%|██████████| 3697/3697 [35:10<00:00,  1.75it/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# FAISS index\nInitializes a FAISS index (IndexFlatIP) designed for cosine similarity search (because your features are L2-normalized) and then populates it with all the extracted features from image collection. ","metadata":{}},{"cell_type":"code","source":"# Build FAISS index\nindex = faiss.IndexFlatIP(image_features.shape[1])\nindex.add(image_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T15:04:06.584498Z","iopub.execute_input":"2025-07-14T15:04:06.584780Z","iopub.status.idle":"2025-07-14T15:04:07.560654Z","shell.execute_reply.started":"2025-07-14T15:04:06.584758Z","shell.execute_reply":"2025-07-14T15:04:07.559805Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Search functions and Gradio-based demo","metadata":{}},{"cell_type":"code","source":"def search_by_image_cnn(query_image, top_k=TOP_K):\n    image = cnn_preprocess(query_image.convert(\"RGB\")).unsqueeze(0).to(device)\n    with torch.no_grad():\n        image_features_query = cnn_model(image).squeeze(-1).squeeze(-1)\n        image_features_query = image_features_query / image_features_query.norm(dim=-1, keepdim=True)\n    image_features_query = image_features_query.cpu().numpy().astype(\"float32\")\n    D, I = index.search(image_features_query, top_k)\n    return [image_paths[i] for i in I[0]]\n\ndef visual_search_cnn(image_query):\n    if image_query is not None:\n        results = search_by_image_cnn(image_query)\n        return [Image.open(p) for p in results]\n    else:\n        return []\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# CNN Visual Search Engine (Image-to-Image)\")\n    image_input = gr.Image(type=\"pil\", label=\"Upload an image to search\")\n    output_gallery = gr.Gallery(label=\"Top Results\", columns=5, height=\"auto\")\n    search_btn = gr.Button(\"Search\")\n    search_btn.click(\n        fn=visual_search_cnn,\n        inputs=image_input,\n        outputs=output_gallery\n    )\n\ndemo.launch()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T15:04:12.239807Z","iopub.execute_input":"2025-07-14T15:04:12.240142Z","iopub.status.idle":"2025-07-14T15:04:13.911114Z","shell.execute_reply.started":"2025-07-14T15:04:12.240116Z","shell.execute_reply":"2025-07-14T15:04:13.910391Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\nIt looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://abb2c4a19eeebb14b1.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://abb2c4a19eeebb14b1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}